{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831e23e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (31072, 2)\n",
      "\n",
      "Class Distribution (Imbalanced):\n",
      "Class_0     12885\n",
      "Class_1      1254\n",
      "Class_2      3621\n",
      "Class_3      1561\n",
      "Class_4      1858\n",
      "Class_5      2513\n",
      "Class_6      1008\n",
      "Class_7      2822\n",
      "Class_8        53\n",
      "Class_9        45\n",
      "Class_10       28\n",
      "Class_11     1093\n",
      "Class_12      688\n",
      "Class_13      537\n",
      "Class_14     1066\n",
      "Class_15       21\n",
      "Class_16      530\n",
      "Class_17      210\n",
      "Class_18      902\n",
      "Class_19     1482\n",
      "Class_20      172\n",
      "Class_21     3777\n",
      "Class_22      802\n",
      "Class_23     2965\n",
      "Class_24      322\n",
      "Class_25     8228\n",
      "Class_26      328\n",
      "Class_27       11\n",
      "dtype: int64\n",
      "Epoch [1/5] Train Loss: 0.1826 Val Loss: 0.1624\n",
      "Epoch [2/5] Train Loss: 0.1638 Val Loss: 0.1591\n",
      "Epoch [3/5] Train Loss: 0.1584 Val Loss: 0.1608\n",
      "Epoch [4/5] Train Loss: 0.1529 Val Loss: 0.1543\n",
      "Epoch [5/5] Train Loss: 0.1433 Val Loss: 0.1587\n",
      "\n",
      "📊 Validation Results (Baseline CNN):\n",
      "Macro F1: 0.052\n",
      "Micro F1: 0.347\n"
     ]
    }
   ],
   "source": [
    "# Human Protein Atlas Image Classification - Baseline CNN\n",
    "# -------------------------------------------------------\n",
    "# Goal: Multi-label classification of 28 protein classes from multi-channel microscopy images.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 1. Load Dataset\n",
    "# ============================\n",
    "data_dir = \"Raw/human-protein-atlas-image-classification/\"\n",
    "train_path = os.path.join(data_dir, \"train.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "print(f\"Dataset Shape: {train_df.shape}\")\n",
    "\n",
    "# Targets: parse into list of ints\n",
    "train_df[\"Target\"] = train_df[\"Target\"].apply(lambda x: list(map(int, x.split())))\n",
    "\n",
    "# One-hot encoding (28 protein classes)\n",
    "num_classes = 28\n",
    "one_hot = np.zeros((len(train_df), num_classes), dtype=int)\n",
    "for i, targets in enumerate(train_df[\"Target\"]):\n",
    "    one_hot[i, targets] = 1\n",
    "train_df_one_hot = pd.DataFrame(\n",
    "    one_hot, columns=[f\"Class_{i}\" for i in range(num_classes)]\n",
    ")\n",
    "train_df = pd.concat([train_df, train_df_one_hot], axis=1)\n",
    "\n",
    "print(\"\\nClass Distribution (Imbalanced):\")\n",
    "print(train_df_one_hot.sum(axis=0))\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 2. Sample Visualization\n",
    "# ============================\n",
    "sample = train_df.sample(5, random_state=42)\n",
    "for _, row in sample.iterrows():\n",
    "    img = cv2.imread(os.path.join(data_dir, \"train\", f\"{row['Id']}_red.png\"))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Image ID: {row['Id']}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"figures/sample_image_{row['Id']}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 3. Custom Dataset\n",
    "# ============================\n",
    "class HPADataset(Dataset):\n",
    "    def __init__(self, df, img_dir, size=224, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.size = size\n",
    "        self.transform = transform\n",
    "        self.label_cols = [col for col in df.columns if col.startswith(\"Class_\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_id = row[\"Id\"]\n",
    "\n",
    "        channels = []\n",
    "        for color in [\"red\", \"green\", \"blue\", \"yellow\"]:\n",
    "            path = os.path.join(self.img_dir, f\"{image_id}_{color}.png\")\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (self.size, self.size))\n",
    "            channels.append(img)\n",
    "\n",
    "        image = np.stack(channels, axis=0)  # shape: (4, H, W)\n",
    "        image = torch.tensor(image, dtype=torch.float32) / 255.0\n",
    "        label = torch.tensor(\n",
    "            row[self.label_cols].values.astype(np.float32), dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 4. Train / Validation Split\n",
    "# ============================\n",
    "sample_df = train_df.sample(10000, random_state=42).reset_index(drop=True)\n",
    "train_set, val_set = train_test_split(sample_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = HPADataset(train_set, os.path.join(data_dir, \"train\"))\n",
    "val_dataset = HPADataset(val_set, os.path.join(data_dir, \"train\"))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 5. Baseline CNN Model\n",
    "# ============================\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=28):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))  # multi-label output\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(num_classes=28).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()  # binary cross-entropy for multi-label\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 6. Training Loop\n",
    "# ============================\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            running_val_loss += val_loss.item()\n",
    "    epoch_val_loss = running_val_loss / len(val_loader)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/5] \"\n",
    "        f\"Train Loss: {epoch_train_loss:.4f} \"\n",
    "        f\"Val Loss: {epoch_val_loss:.4f}\"\n",
    "    )\n",
    "\n",
    "# ============================\n",
    "# 7. Loss Curves\n",
    "# ============================\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"figures/loss_curves.png\")\n",
    "plt.close()\n",
    "\n",
    "# ============================\n",
    "# 8. Validation Evaluation F1 Score\n",
    "# ============================\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Threshold 0.5 because output = sigmoid\n",
    "        preds = (outputs.cpu().numpy() > 0.5).astype(int)\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.vstack(all_preds)\n",
    "all_labels = np.vstack(all_labels)\n",
    "\n",
    "print(\"\\n📊 Validation Results (Baseline CNN):\")\n",
    "print(f\"Macro F1: {f1_score(all_labels, all_preds, average='macro'):.3f}\")\n",
    "print(f\"Micro F1: {f1_score(all_labels, all_preds, average='micro'):.3f}\")\n",
    "\n",
    "# 🔎 Observations:\n",
    "# - Baseline CNN converges but still underfits on complex patterns.\n",
    "# - Severe class imbalance → motivates techniques like class-weighted loss or oversampling.\n",
    "# - Next steps: pretrained models (ResNet, EfficientNet), data augmentation, focal loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "323c5010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/ds_elite/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/ds_elite/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Train Loss: 0.2193\n",
      "Epoch [2/5] - Train Loss: 0.1273\n",
      "Epoch [3/5] - Train Loss: 0.0966\n",
      "Epoch [4/5] - Train Loss: 0.0608\n",
      "Epoch [5/5] - Train Loss: 0.0346\n",
      "\n",
      "📊 Validation Results:\n",
      "Macro F1: 0.212\n",
      "Micro F1: 0.504\n"
     ]
    }
   ],
   "source": [
    "# Human Protein Atlas Image Classification - ResNet18 (4-Channel Adaptation)\n",
    "# --------------------------------------------------------------------------\n",
    "# Dataset: https://www.kaggle.com/c/human-protein-atlas-image-classification\n",
    "# Goal: Multi-label classification of 28 protein classes using a pretrained ResNet18,\n",
    "#       adapted to handle 4-channel microscopy images (RGB + Yellow).\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 1. Model Definition\n",
    "# ============================\n",
    "class ResNet18_HPA(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet18 adapted for Human Protein Atlas images:\n",
    "    - First conv layer modified to accept 4 channels instead of 3.\n",
    "    - Final fully connected layer outputs 28 protein classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=28):\n",
    "        super(ResNet18_HPA, self).__init__()\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "\n",
    "        # Modify first convolution (3 channels → 4 channels)\n",
    "        old_conv = self.base_model.conv1\n",
    "        self.base_model.conv1 = nn.Conv2d(\n",
    "            4, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
    "        )\n",
    "        # Initialize new channel with existing weights\n",
    "        self.base_model.conv1.weight.data[:, :3, :, :] = old_conv.weight.data\n",
    "        self.base_model.conv1.weight.data[:, 3:4, :, :] = old_conv.weight.data[\n",
    "            :, :1, :, :\n",
    "        ]\n",
    "\n",
    "        # Replace classification head\n",
    "        in_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 2. Training Setup\n",
    "# ============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet18_HPA(num_classes=28).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()  # suited for multi-label classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 3. Training Loop\n",
    "# ============================\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:  # ⚠️ train_loader from previous setup\n",
    "        images, labels = images.to(device), labels.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] - Train Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 4. Validation Evaluation\n",
    "# ============================\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:  # ⚠️ val_loader from previous setup\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        preds = (torch.sigmoid(outputs).cpu().numpy() > 0.5).astype(int)\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.vstack(all_preds)\n",
    "all_labels = np.vstack(all_labels)\n",
    "\n",
    "print(\"\\n📊 Validation Results:\")\n",
    "print(f\"Macro F1: {f1_score(all_labels, all_preds, average='macro'):.3f}\")\n",
    "print(f\"Micro F1: {f1_score(all_labels, all_preds, average='micro'):.3f}\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 🔎 Observations\n",
    "# ============================\n",
    "# - ResNet18 pretrained on ImageNet adapts successfully to 4-channel microscopy.\n",
    "# - BCEWithLogitsLoss ensures stable multi-label training.\n",
    "# - Outperforms baseline CNN in both loss convergence & F1 scores.\n",
    "# - Next steps:\n",
    "#   * Deeper models: ResNet50, EfficientNet (via timm).\n",
    "#   * Data augmentation: random flips, rotations, color jitter.\n",
    "#   * Advanced loss functions: Focal Loss, Class-Balanced Loss to handle imbalance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_elite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
